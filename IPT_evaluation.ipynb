{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM_IPT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cB87fpiQbTET",
        "y0GsZd3khtu_",
        "DRBKQvd_hfmK"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrEAVB/x3OcoVFzbl1uU/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjgonzalezGUD/TFM_denoising_transformers/blob/main/IPT_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnWbeaHJVUOA",
        "outputId": "43c4ceb5-97bb-449d-9424-aa405647b5af"
      },
      "source": [
        "\n",
        "!pip install torch==1.4.0 torchvision==0.5.0 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
        "!pip install matplotlib \n",
        "!pip install scikit-image  \n",
        "!pip install tqdm\n",
        "!pip install einops\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC9rPV8hoHmb",
        "outputId": "56a32963-c029-414f-e528-cb37ae9e39ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANcsWW3OoM_A",
        "outputId": "efabad6f-d65c-4ec0-e0e7-6ab3338f3cd7"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuG7aiYiYfTl"
      },
      "source": [
        "#DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tBCUCqEYszt"
      },
      "source": [
        "_init_.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YtHrla8YGCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f66a800-2486-420f-e5a6-56c4a98080f0"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile datainit_IPT.py\n",
        "from importlib import import_module\n",
        "#from dataloader import MSDataLoader\n",
        "from torch.utils.data import dataloader\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "# This is a simple wrapper function for ConcatDataset\n",
        "class MyConcatDataset(ConcatDataset):\n",
        "    def __init__(self, datasets):\n",
        "        super(MyConcatDataset, self).__init__(datasets)\n",
        "        self.train = datasets[0].train\n",
        "\n",
        "    def set_scale(self, idx_scale):\n",
        "        for d in self.datasets:\n",
        "            if hasattr(d, 'set_scale'): d.set_scale(idx_scale)\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, args):\n",
        "        self.loader_train = None\n",
        "        print (args.test_only)\n",
        "        if not args.test_only:\n",
        "            datasets = []\n",
        "            print (args.data_train)\n",
        "            for d in args.data_train:\n",
        "                module_name = d if d.find('DIV2K-Q') < 0 else 'DIV2KJPEG'\n",
        "                print (module_name.lower())\n",
        "                m = import_module( module_name.lower())\n",
        "                \n",
        "                datasets.append(getattr(m, module_name)(args, name=d))\n",
        "            print (datasets)\n",
        "            self.loader_train = dataloader.DataLoader(\n",
        "                MyConcatDataset(datasets),\n",
        "                batch_size=args.batch_size,\n",
        "                shuffle=True,\n",
        "                pin_memory=not args.cpu,\n",
        "                num_workers=args.n_threads,\n",
        "            )\n",
        "            print (self.loader_train)\n",
        "\n",
        "        self.loader_test = []\n",
        "        print (args.data_test)\n",
        "        for d in args.data_test:\n",
        "            print (d)\n",
        "            m = import_module('benchmark')\n",
        "            testset = getattr(m, 'Benchmark')(args, train=False, name=d)\n",
        "            self.loader_test.append(\n",
        "                dataloader.DataLoader(\n",
        "                    testset,\n",
        "                    batch_size=args.test_batch_size,\n",
        "                    shuffle=False,\n",
        "                    pin_memory=not args.cpu,\n",
        "                    num_workers=args.n_threads,\n",
        "                )\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting datainit_IPT.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swWcEPxHZjF1"
      },
      "source": [
        "common.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h96mAQBxZidG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bb7613-30d3-4f6d-9e34-0822b2055285"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile common.py\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import skimage.color as sc\n",
        "\n",
        "import torch\n",
        "\n",
        "def get_patch(*args, patch_size=96, scale=2, multi=False, input_large=False):\n",
        "    ih, iw = args[0].shape[:2]\n",
        "\n",
        "    tp = patch_size\n",
        "    ip = tp // scale\n",
        "\n",
        "    ix = random.randrange(0, iw - ip + 1)\n",
        "    iy = random.randrange(0, ih - ip + 1)\n",
        "\n",
        "    if not input_large:\n",
        "        tx, ty = scale * ix, scale * iy\n",
        "    else:\n",
        "        tx, ty = ix, iy\n",
        "\n",
        "    ret = [\n",
        "        args[0][iy:iy + ip, ix:ix + ip, :],\n",
        "        *[a[ty:ty + tp, tx:tx + tp, :] for a in args[1:]]\n",
        "    ]\n",
        "\n",
        "    return ret\n",
        "\n",
        "def set_channel(*args, n_channels=3):\n",
        "    def _set_channel(img):\n",
        "        if img.ndim == 2:\n",
        "            img = np.expand_dims(img, axis=2)\n",
        "\n",
        "        c = img.shape[2]\n",
        "        if n_channels == 1 and c == 3:\n",
        "            img = np.expand_dims(sc.rgb2ycbcr(img)[:, :, 0], 2)\n",
        "        elif n_channels == 3 and c == 1:\n",
        "            img = np.concatenate([img] * n_channels, 2)\n",
        "\n",
        "        return img[:,:,:n_channels]\n",
        "\n",
        "    return [_set_channel(a) for a in args]\n",
        "\n",
        "def np2Tensor(*args, rgb_range=255):\n",
        "    def _np2Tensor(img):\n",
        "        np_transpose = np.ascontiguousarray(img.transpose((2, 0, 1)))\n",
        "        tensor = torch.from_numpy(np_transpose).float()\n",
        "        tensor.mul_(rgb_range / 255)\n",
        "\n",
        "        return tensor\n",
        "\n",
        "    return [_np2Tensor(a) for a in args]\n",
        "\n",
        "def augment(*args, hflip=True, rot=True):\n",
        "    hflip = hflip and random.random() < 0.5\n",
        "    vflip = rot and random.random() < 0.5\n",
        "    rot90 = rot and random.random() < 0.5\n",
        "\n",
        "    def _augment(img):\n",
        "        if hflip: img = img[:, ::-1, :]\n",
        "        if vflip: img = img[::-1, :, :]\n",
        "        if rot90: img = img.transpose(1, 0, 2)\n",
        "        \n",
        "        return img\n",
        "\n",
        "    return [_augment(a) for a in args]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting common.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsVWQ2YTZaPW"
      },
      "source": [
        "srdata.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHW62BOdZXft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850f8816-45e6-4356-9ecb-bac18ad5ecd9"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile srdata.py\n",
        "execfile('common.py')\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pickle\n",
        "import io\n",
        "\n",
        "import PIL.Image as pil_image\n",
        "import common\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as tfs\n",
        "\n",
        "def search(root, target=\"JPEG\"):\n",
        "    item_list = []\n",
        "    items = os.listdir(root)\n",
        "    for item in items:\n",
        "        path = os.path.join(root, item)\n",
        "        if os.path.isdir(path):\n",
        "            #print('[-]', path)\n",
        "            item_list.extend(search(path, target))\n",
        "        elif path.split('/')[-1].startswith(target):\n",
        "            item_list.append(path)\n",
        "        elif path.split('/')[-2] == target or path.split('/')[-3] == target or path.split('/')[-4] == target:\n",
        "            item_list.append(path)\n",
        "        else:\n",
        "            ttt = 1\n",
        "            #print('[!]', path)\n",
        "    return item_list\n",
        "\n",
        "class SRData(data.Dataset):\n",
        "    def __init__(self, args, name='', train=True, benchmark=False):\n",
        "        self.args = args\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.split = 'train' if train else 'test'\n",
        "        self.do_eval = True\n",
        "        self.benchmark = benchmark\n",
        "        self.input_large = (args.model == 'VDSR')\n",
        "        self.scale = args.scale\n",
        "        self.idx_scale = 0\n",
        "        \n",
        "        if self.args.derain:\n",
        "            self.derain_dataroot = os.path.join(args.dir_data, \"RainTrainL\")\n",
        "            self.derain_img_list = search(self.derain_dataroot, \"rainstreak\")\n",
        "            self.derain_test = os.path.join(args.dir_data, \"Rain100L\")\n",
        "            self.derain_lr_test = search(self.derain_test, \"rain\")\n",
        "            self.derain_hr_test = [path.replace(\"rainy/\",\"no\") for path in self.derain_lr_test]\n",
        "        if self.args.deblur:\n",
        "            self.deblur_dataroot = os.path.join(args.dir_data, \"GOPRO_Large/train\")\n",
        "            self.deblur_hr = search(self.deblur_dataroot, \"sharp\")\n",
        "            self.deblur_lr = search(self.deblur_dataroot, \"blur\")\n",
        "            self.deblur_test = os.path.join(args.dir_data, \"GOPRO_Large/test\")\n",
        "            self.deblur_hr_test = search(self.deblur_test, \"sharp\")\n",
        "            self.deblur_lr_test = search(self.deblur_test, \"blur\")\n",
        "\n",
        "        self._set_filesystem(args.dir_data)\n",
        "        if args.ext.find('img') < 0:\n",
        "            path_bin = os.path.join(self.apath, 'bin')\n",
        "            os.makedirs(path_bin, exist_ok=True)\n",
        "\n",
        "        list_hr, list_lr = self._scan()\n",
        "        if args.ext.find('img') >= 0 or benchmark:\n",
        "            self.images_hr, self.images_lr = list_hr, list_lr\n",
        "        elif args.ext.find('sep') >= 0:\n",
        "            os.makedirs(\n",
        "                self.dir_hr.replace(self.apath, path_bin),\n",
        "                exist_ok=True\n",
        "            )\n",
        "            for s in self.scale:\n",
        "                if s == 1:\n",
        "                    os.makedirs(\n",
        "                        os.path.join(self.dir_hr),\n",
        "                        exist_ok=True\n",
        "                    )\n",
        "                else:\n",
        "                    os.makedirs(\n",
        "                        os.path.join(\n",
        "                            self.dir_lr.replace(self.apath, path_bin),\n",
        "                            'X{}'.format(s)\n",
        "                        ),\n",
        "                        exist_ok=True\n",
        "                    )\n",
        "            \n",
        "            self.images_hr, self.images_lr = [], [[] for _ in self.scale]\n",
        "            for h in list_hr:\n",
        "                b = h.replace(self.apath, path_bin)\n",
        "                b = b.replace(self.ext[0], '.pt')\n",
        "                self.images_hr.append(b)\n",
        "                self._check_and_load(args.ext, h, b, verbose=True) \n",
        "            for i, ll in enumerate(list_lr):\n",
        "                for l in ll:\n",
        "                    b = l.replace(self.apath, path_bin)\n",
        "                    b = b.replace(self.ext[1], '.pt')\n",
        "                    self.images_lr[i].append(b)\n",
        "                    self._check_and_load(args.ext, l, b, verbose=True) \n",
        "        if train:\n",
        "            n_patches = args.batch_size * args.test_every\n",
        "            n_images = len(args.data_train) * len(self.images_hr)\n",
        "            if n_images == 0:\n",
        "                self.repeat = 0\n",
        "            else:\n",
        "                self.repeat = max(n_patches // n_images, 1)\n",
        "\n",
        "    # Below functions as used to prepare images\n",
        "    def _scan(self):\n",
        "        names_hr = sorted(\n",
        "            glob.glob(os.path.join(self.dir_hr, '*' + self.ext[0]))\n",
        "        )\n",
        "        names_lr = [[] for _ in self.scale]\n",
        "        for f in names_hr:\n",
        "            filename, _ = os.path.splitext(os.path.basename(f))\n",
        "            for si, s in enumerate(self.scale):\n",
        "                if s != 1:\n",
        "                    names_lr[si].append(os.path.join(\n",
        "                        self.dir_lr, 'X{}/{}x{}{}'.format(\n",
        "                            s, filename, s, self.ext[1]\n",
        "                        )\n",
        "                    ))\n",
        "        for si, s in enumerate(self.scale):\n",
        "            if s == 1:\n",
        "                names_lr[si]=names_hr\n",
        "        return names_hr, names_lr\n",
        "\n",
        "    def _set_filesystem(self, dir_data):\n",
        "        self.apath = os.path.join(dir_data, self.name)\n",
        "        self.dir_hr = os.path.join(self.apath, 'HR')\n",
        "        self.dir_lr = os.path.join(self.apath, 'LR_bicubic')\n",
        "        #if self.input_large: self.dir_lr += 'L'\n",
        "        self.ext = ('.png', '.png')\n",
        "\n",
        "    def _check_and_load(self, ext, img, f, verbose=True):\n",
        "        if not os.path.isfile(f) or ext.find('reset') >= 0:\n",
        "            if verbose:\n",
        "                print('Making a binary: {}'.format(f))\n",
        "            with open(f, 'wb') as _f:\n",
        "                pickle.dump(imageio.imread(img), _f)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.args.deblur:\n",
        "            lr, hr, filename = self._load_file_deblur(idx, False)\n",
        "            pair = self.get_patch(lr, hr)\n",
        "            pair = common.set_channel(*pair, n_channels=self.args.n_colors)\n",
        "            pair_t = common.np2Tensor(*pair, rgb_range=self.args.rgb_range)\n",
        "            return pair_t[0], pair_t[1], filename\n",
        "        if self.args.derain:\n",
        "            norain, rain, filename = self._load_rain_test(idx)\n",
        "            pair = common.set_channel(*[norain, rain], n_channels=self.args.n_colors)\n",
        "            pair_t = common.np2Tensor(*pair, rgb_range=self.args.rgb_range)\n",
        "            return pair_t[0], pair_t[1], filename\n",
        "        if self.args.denoise:\n",
        "            hr, filename = self._load_file_hr(idx)\n",
        "            pair = self.get_patch_hr(hr)\n",
        "            pair = common.set_channel(*[pair], n_channels=self.args.n_colors)\n",
        "            pair_t = common.np2Tensor(*pair, rgb_range=self.args.rgb_range)\n",
        "            return pair_t[0],pair_t[0], filename\n",
        "        lr, hr, filename = self._load_file(idx)\n",
        "        pair = self.get_patch(lr, hr)\n",
        "        pair = common.set_channel(*pair, n_channels=self.args.n_colors)\n",
        "        pair_t = common.np2Tensor(*pair, rgb_range=self.args.rgb_range)\n",
        "        return pair_t[0], pair_t[1], filename\n",
        "        print (lr, hr, filename)\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return len(self.images_hr) * self.repeat\n",
        "        else:\n",
        "            if self.args.derain:\n",
        "                return int(len(self.derain_hr_test)/self.args.derain_test)\n",
        "            if self.args.deblur:\n",
        "                return int(len(self.deblur_hr_test)/self.args.deblur_test)\n",
        "            return len(self.images_hr)\n",
        "\n",
        "    def _get_index(self, idx):\n",
        "        if self.train:\n",
        "            return idx % len(self.images_hr)\n",
        "        else:\n",
        "            #if self.args.deblur:\n",
        "            #    return random.randint(0, len(self.deblur_hr_test) - 1)\n",
        "            #if self.args.dehaze:\n",
        "            #    return random.randint(0, len(self.haze_test) - 1)\n",
        "            return idx\n",
        "\n",
        "    def _load_file_hr(self, idx):\n",
        "        idx = self._get_index(idx)\n",
        "        f_hr = self.images_hr[idx]\n",
        "\n",
        "        filename, _ = os.path.splitext(os.path.basename(f_hr))\n",
        "        if self.args.ext == 'img' or self.benchmark:\n",
        "            hr = imageio.imread(f_hr)\n",
        "        elif self.args.ext.find('sep') >= 0:\n",
        "            with open(f_hr, 'rb') as _f:\n",
        "                hr = pickle.load(_f)\n",
        "\n",
        "        return hr, filename\n",
        "    \n",
        "    def _load_rain_test(self, idx):\n",
        "        f_hr = self.derain_hr_test[idx]\n",
        "        f_lr = self.derain_lr_test[idx]\n",
        "        filename, _ = os.path.splitext(os.path.basename(f_lr))\n",
        "        norain = imageio.imread(f_hr)\n",
        "        rain = imageio.imread(f_lr)\n",
        "        return norain, rain, filename\n",
        "    \n",
        "    def _load_file(self, idx):\n",
        "        idx = self._get_index(idx)\n",
        "       \n",
        "        f_hr = self.images_hr[idx]\n",
        "        f_lr = self.images_lr[self.idx_scale][idx]\n",
        "\n",
        "        filename, _ = os.path.splitext(os.path.basename(f_hr))\n",
        "        if self.args.ext == 'img' or self.benchmark:\n",
        "            hr = imageio.imread(f_hr)\n",
        "            lr = imageio.imread(f_lr)\n",
        "        elif self.args.ext.find('sep') >= 0:\n",
        "            with open(f_hr, 'rb') as _f:\n",
        "                hr = pickle.load(_f)\n",
        "            with open(f_lr, 'rb') as _f:\n",
        "                lr = pickle.load(_f)\n",
        "\n",
        "        return lr, hr, filename\n",
        "    \n",
        "    def _load_file_deblur(self, idx, train = True):\n",
        "        idx = self._get_index(idx)\n",
        "        if train:\n",
        "            f_hr = self.images_hr[idx]\n",
        "            f_lr = self.images_lr[idx]\n",
        "        else:\n",
        "            f_hr = self.deblur_hr_test[idx]\n",
        "            f_lr = self.deblur_lr_test[idx]\n",
        "        \n",
        "        filename, _ = os.path.splitext(os.path.basename(f_hr))\n",
        "        filename = f_hr[-27:-17] + filename\n",
        "        hr = imageio.imread(f_hr)\n",
        "        lr = imageio.imread(f_lr)\n",
        "\n",
        "        return lr, hr, filename\n",
        "\n",
        "    def get_patch_hr(self, hr):\n",
        "        scale = self.scale[self.idx_scale]\n",
        "        if self.train:\n",
        "            hr = self.get_patch_img_hr(\n",
        "                hr,\n",
        "                patch_size=self.args.patch_size,\n",
        "                scale=1\n",
        "            )\n",
        "\n",
        "        return hr\n",
        "\n",
        "    def get_patch_img_hr(self, img, patch_size=96, scale=2):\n",
        "        ih, iw = img.shape[:2]\n",
        "\n",
        "        tp = patch_size\n",
        "        ip = tp // scale\n",
        "\n",
        "        ix = random.randrange(0, iw - ip + 1)\n",
        "        iy = random.randrange(0, ih - ip + 1)\n",
        "\n",
        "        ret = img[iy:iy + ip, ix:ix + ip, :]\n",
        "\n",
        "        return ret\n",
        "\n",
        "    \n",
        "    def get_patch(self, lr, hr):\n",
        "        scale = self.scale[self.idx_scale]\n",
        "        if self.train:\n",
        "            lr, hr = common.get_patch(\n",
        "                lr, hr,\n",
        "                patch_size=self.args.patch_size*scale,\n",
        "                scale=scale,\n",
        "                multi=(len(self.scale) > 1)\n",
        "            )\n",
        "            if not self.args.no_augment: lr, hr = common.augment(lr, hr)\n",
        "        else:\n",
        "            ih, iw = lr.shape[:2]\n",
        "            hr = hr[0:ih * scale, 0:iw * scale]\n",
        "\n",
        "        return lr, hr\n",
        "\n",
        "    def set_scale(self, idx_scale):\n",
        "        if not self.input_large:\n",
        "            self.idx_scale = idx_scale\n",
        "        else:\n",
        "            self.idx_scale = random.randint(0, len(self.scale) - 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting srdata.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COYqTYOkYxM1"
      },
      "source": [
        "benchmark.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-lW-V6oYrSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52164b12-532b-4988-9acc-d3e2f4fcbea1"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile data.benchmark.py\n",
        "\n",
        "execfile('common.py')\n",
        "execfile('srdata.py')\n",
        "import os\n",
        "import common\n",
        "import srdata\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class Benchmark(srdata.SRData):\n",
        "    def __init__(self, args, name='', train=True, benchmark=True):\n",
        "        super(Benchmark, self).__init__(\n",
        "            args, name=name, train=train, benchmark=True\n",
        "        )\n",
        "\n",
        "    def _set_filesystem(self, dir_data):\n",
        "        self.apath = os.path.join(dir_data, 'benchmark', self.name)\n",
        "        self.dir_hr = os.path.join(self.apath, 'HR')\n",
        "        if self.input_large:\n",
        "            self.dir_lr = os.path.join(self.apath, 'LR_bicubicL')\n",
        "        else:\n",
        "            self.dir_lr = os.path.join(self.apath, 'LR_bicubic')\n",
        "        self.ext = ('', '.png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data.benchmark.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTjhEMYRZ_ov"
      },
      "source": [
        "demo.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfyJvTbQaC78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b394d473-f286-491b-8fe2-998e3a2191b1"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile demo.py\n",
        "import os\n",
        "execfile('common.py')\n",
        "import common\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "class Demo(data.Dataset):\n",
        "    def __init__(self, args, name='Demo', train=False, benchmark=False):\n",
        "        self.args = args\n",
        "        self.name = name\n",
        "        self.scale = args.scale\n",
        "        self.idx_scale = 0\n",
        "        self.train = False\n",
        "        self.benchmark = benchmark\n",
        "\n",
        "        self.filelist = []\n",
        "        for f in os.listdir(args.dir_demo):\n",
        "            if f.find('.png') >= 0 or f.find('.jp') >= 0:\n",
        "                self.filelist.append(os.path.join(args.dir_demo, f))\n",
        "        self.filelist.sort()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = os.path.splitext(os.path.basename(self.filelist[idx]))[0]\n",
        "        lr = imageio.imread(self.filelist[idx])\n",
        "        lr, = common.set_channel(lr, n_channels=self.args.n_colors)\n",
        "        lr_t, = common.np2Tensor(lr, rgb_range=self.args.rgb_range)\n",
        "\n",
        "        return lr_t, -1, filename\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filelist)\n",
        "\n",
        "    def set_scale(self, idx_scale):\n",
        "        self.idx_scale = idx_scale\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYDiC-KWaHUF"
      },
      "source": [
        "div2k.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtm3t62_aJU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4bec9d6-71c4-46f2-f989-e4fbf421c584"
      },
      "source": [
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile div2k.py\n",
        "execfile('srdata.py')\n",
        "import os\n",
        "import srdata\n",
        "\n",
        "class DIV2K(SRData):\n",
        "    def __init__(self, args, name='DIV2K', train=True, benchmark=False):\n",
        "        data_range = [r.split('-') for r in args.data_range.split('/')]\n",
        "        if train:\n",
        "            data_range = data_range[0]\n",
        "        else:\n",
        "            if args.test_only and len(data_range) == 1:\n",
        "                data_range = data_range[0]\n",
        "            else:\n",
        "                data_range = data_range[1]\n",
        "\n",
        "        self.begin, self.end = list(map(lambda x: int(x), data_range))\n",
        "        super(DIV2K, self).__init__(\n",
        "            args, name=name, train=train, benchmark=benchmark\n",
        "        )\n",
        "\n",
        "    def _scan(self):\n",
        "        names_hr, names_lr = super(DIV2K, self)._scan()\n",
        "        names_hr = names_hr[self.begin - 1:self.end]\n",
        "        names_lr = [n[self.begin - 1:self.end] for n in names_lr]\n",
        "\n",
        "        return names_hr, names_lr\n",
        "\n",
        "    def _set_filesystem(self, dir_data):\n",
        "        super(DIV2K, self)._set_filesystem(dir_data)\n",
        "        self.dir_hr = os.path.join(self.apath, 'DIV2K_train_HR')\n",
        "        self.dir_lr = os.path.join(self.apath, 'DIV2K_train_LR_bicubic')\n",
        "        #if self.input_large: self.dir_lr += 'L'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting div2k.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-x1HzJbaVCu"
      },
      "source": [
        "div2kjpeg.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYofhB6JaNqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c978398-3f11-4126-d459-4724f115d533"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile div2kjpeg.py\n",
        "execfile('div2k.py')\n",
        "execfile('srdata.py')\n",
        "\n",
        "import os\n",
        "import srdata\n",
        "import div2k\n",
        "\n",
        "class DIV2KJPEG(DIV2K):\n",
        "    def __init__(self, args, name='', train=True, benchmark=False):\n",
        "        self.q_factor = int(name.replace('DIV2K-Q', ''))\n",
        "        super(DIV2KJPEG, self).__init__(\n",
        "            args, name=name, train=train, benchmark=benchmark\n",
        "        )\n",
        "\n",
        "    def _set_filesystem(self, dir_data):\n",
        "        self.apath = os.path.join(dir_data, 'DIV2K')\n",
        "        self.dir_hr = os.path.join(self.apath, 'DIV2K_train_HR')\n",
        "        self.dir_lr = os.path.join(\n",
        "            self.apath, 'DIV2K_Q{}'.format(self.q_factor)\n",
        "        )\n",
        "        if self.input_large: self.dir_lr += 'L'\n",
        "        self.ext = ('.png', '.jpg')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting div2kjpeg.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SW_eLkXanQV"
      },
      "source": [
        "sr291.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9fzQlXzaqNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c963c2-db85-4e8f-f260-ae983fcf2751"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile sr291.py\n",
        "execfile('srdata.py')\n",
        "import srdata\n",
        "\n",
        "class SR291(SRData):\n",
        "    def __init__(self, args, name='SR291', train=True, benchmark=False):\n",
        "        super(SR291, self).__init__(args, name=name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sr291.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzygiiscbFsM"
      },
      "source": [
        "#LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNv6HHwcbJC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46e08ce-449b-4512-eda6-5cb4d1c65e9c"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile loss.py\n",
        "import os\n",
        "from importlib import import_module\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Loss(nn.modules.loss._Loss):\n",
        "    def __init__(self, args, ckp):\n",
        "        super(Loss, self).__init__()\n",
        "        print('Preparing loss function:')\n",
        "\n",
        "        self.n_GPUs = args.n_GPUs\n",
        "        self.loss = []\n",
        "        self.loss_module = nn.ModuleList()\n",
        "        for loss in args.loss.split('+'):\n",
        "            weight, loss_type = loss.split('*')\n",
        "            if loss_type == 'MSE':\n",
        "                loss_function = nn.MSELoss()\n",
        "            elif loss_type == 'L1':\n",
        "                loss_function = nn.L1Loss()\n",
        "\n",
        "            self.loss.append({\n",
        "                'type': loss_type,\n",
        "                'weight': float(weight),\n",
        "                'function': loss_function}\n",
        "            )\n",
        "\n",
        "        if len(self.loss) > 1:\n",
        "            self.loss.append({'type': 'Total', 'weight': 0, 'function': None})\n",
        "\n",
        "        for l in self.loss:\n",
        "            if l['function'] is not None:\n",
        "                print('{:.3f} * {}'.format(l['weight'], l['type']))\n",
        "                self.loss_module.append(l['function'])\n",
        "\n",
        "        self.log = torch.Tensor()\n",
        "\n",
        "        device = torch.device('cpu' if args.cpu else 'cuda')\n",
        "        self.loss_module.to(device)\n",
        "        if args.precision == 'half': self.loss_module.half()\n",
        "        if not args.cpu and args.n_GPUs > 1:\n",
        "            self.loss_module = nn.DataParallel(\n",
        "                self.loss_module, range(args.n_GPUs)\n",
        "            )\n",
        "\n",
        "        if args.load != '': self.load(ckp.dir, cpu=args.cpu)\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        losses = []\n",
        "        for i, l in enumerate(self.loss):\n",
        "            if l['function'] is not None:\n",
        "                loss = l['function'](sr, hr)\n",
        "                effective_loss = l['weight'] * loss\n",
        "                losses.append(effective_loss)\n",
        "                self.log[-1, i] += effective_loss.item()\n",
        "            elif l['type'] == 'DIS':\n",
        "                self.log[-1, i] += self.loss[i - 1]['function'].loss\n",
        "\n",
        "        loss_sum = sum(losses)\n",
        "        if len(self.loss) > 1:\n",
        "            self.log[-1, -1] += loss_sum.item()\n",
        "\n",
        "        return loss_sum\n",
        "\n",
        "    def step(self):\n",
        "        for l in self.get_loss_module():\n",
        "            if hasattr(l, 'scheduler'):\n",
        "                l.scheduler.step()\n",
        "\n",
        "    def start_log(self):\n",
        "        self.log = torch.cat((self.log, torch.zeros(1, len(self.loss))))\n",
        "\n",
        "    def end_log(self, n_batches):\n",
        "        self.log[-1].div_(n_batches)\n",
        "\n",
        "    def display_loss(self, batch):\n",
        "        n_samples = batch + 1\n",
        "        log = []\n",
        "        for l, c in zip(self.loss, self.log[-1]):\n",
        "            log.append('[{}: {:.4f}]'.format(l['type'], c / n_samples))\n",
        "\n",
        "        return ''.join(log)\n",
        "\n",
        "    def plot_loss(self, apath, epoch):\n",
        "        axis = np.linspace(1, epoch, epoch)\n",
        "        for i, l in enumerate(self.loss):\n",
        "            label = '{} Loss'.format(l['type'])\n",
        "            fig = plt.figure()\n",
        "            plt.title(label)\n",
        "            plt.plot(axis, self.log[:, i].numpy(), label=label)\n",
        "            plt.legend()\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(apath, 'loss_{}.pdf'.format(l['type'])))\n",
        "            plt.close(fig)\n",
        "\n",
        "    def get_loss_module(self):\n",
        "        if self.n_GPUs == 1:\n",
        "            return self.loss_module\n",
        "        else:\n",
        "            return self.loss_module.module\n",
        "\n",
        "    def save(self, apath):\n",
        "        torch.save(self.state_dict(), os.path.join(apath, 'loss.pt'))\n",
        "        torch.save(self.log, os.path.join(apath, 'loss_log.pt'))\n",
        "\n",
        "    def load(self, apath, cpu=False):\n",
        "        if cpu:\n",
        "            kwargs = {'map_location': lambda storage, loc: storage}\n",
        "        else:\n",
        "            kwargs = {}\n",
        "\n",
        "        self.load_state_dict(torch.load(\n",
        "            os.path.join(apath, 'loss.pt'),\n",
        "            **kwargs\n",
        "        ))\n",
        "        self.log = torch.load(os.path.join(apath, 'loss_log.pt'))\n",
        "        for l in self.get_loss_module():\n",
        "            if hasattr(l, 'scheduler'):\n",
        "                for _ in range(len(self.log)): l.scheduler.step()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting loss.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB87fpiQbTET"
      },
      "source": [
        "#MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsa0FcQIbeV1"
      },
      "source": [
        "_init_.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqQhLjHtbUYd",
        "outputId": "eb447efe-75bb-44d7-aeb7-0c3dbab9d108"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile model.py\n",
        "import os\n",
        "from importlib import import_module\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel as P\n",
        "import torch.utils.model_zoo\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, args, ckp):\n",
        "        super(Model, self).__init__()\n",
        "        print('Making model...')\n",
        "        self.args = args\n",
        "        self.scale = args.scale\n",
        "        self.patch_size = args.patch_size\n",
        "        self.idx_scale = 0\n",
        "        self.input_large = (args.model == 'VDSR')\n",
        "        self.self_ensemble = args.self_ensemble\n",
        "        self.precision = args.precision\n",
        "        self.cpu = args.cpu\n",
        "        self.device = torch.device('cpu' if args.cpu else 'cuda')\n",
        "        self.n_GPUs = args.n_GPUs\n",
        "        self.save_models = args.save_models\n",
        "        \n",
        "        module = import_module(args.model.lower())\n",
        "        self.model = module.make_model(args).to(self.device)\n",
        "        if args.precision == 'half':\n",
        "            self.model.half()\n",
        "\n",
        "        self.load(\n",
        "            ckp.get_path('model'),\n",
        "            resume=args.resume,\n",
        "            cpu=args.cpu\n",
        "        )\n",
        "        print(self.model, file=ckp.log_file)\n",
        "\n",
        "    def forward(self, x, idx_scale):\n",
        "        self.idx_scale = idx_scale\n",
        "        \n",
        "        if hasattr(self.model, 'set_scale'):\n",
        "            self.model.set_scale(idx_scale)\n",
        "\n",
        "        if self.training:\n",
        "            if self.n_GPUs > 1:\n",
        "                return P.data_parallel(self.model, x, range(self.n_GPUs))\n",
        "            else:\n",
        "                return self.model(x)\n",
        "        else:\n",
        "            forward_function = self.forward_chop\n",
        "\n",
        "            if self.self_ensemble:\n",
        "                return self.forward_x8(x, forward_function=forward_function)\n",
        "            else:\n",
        "                return forward_function(x)\n",
        "\n",
        "    def save(self, apath, epoch, is_best=False):\n",
        "        save_dirs = [os.path.join(apath, 'model_latest.pt')]\n",
        "\n",
        "        if is_best:\n",
        "            save_dirs.append(os.path.join(apath, 'model_best.pt'))\n",
        "        if self.save_models:\n",
        "            save_dirs.append(\n",
        "                os.path.join(apath, 'model_{}.pt'.format(epoch))\n",
        "            )\n",
        "\n",
        "        for s in save_dirs:\n",
        "            torch.save(self.model.state_dict(), s)\n",
        "\n",
        "    def load(self, apath, pre_train='', resume=-1, cpu=False):\n",
        "        load_from = None\n",
        "        kwargs = {}\n",
        "        if cpu:\n",
        "            kwargs = {'map_location': lambda storage, loc: storage}\n",
        "\n",
        "        if resume == -1:\n",
        "            load_from = torch.load(\n",
        "                os.path.join(apath, 'model_latest.pt'),\n",
        "                **kwargs\n",
        "            )\n",
        "        elif resume == 0:\n",
        "            if pre_train == 'download':\n",
        "                print('Download the model')\n",
        "                dir_model = os.path.join('..', 'models')\n",
        "                os.makedirs(dir_model, exist_ok=True)\n",
        "                load_from = torch.utils.model_zoo.load_url(\n",
        "                    self.model.url,\n",
        "                    model_dir=dir_model,\n",
        "                    **kwargs\n",
        "                )\n",
        "        else:\n",
        "            load_from = torch.load(\n",
        "                os.path.join(apath, 'model_{}.pt'.format(resume)),\n",
        "                **kwargs\n",
        "            )\n",
        "\n",
        "        if load_from:\n",
        "            self.model.load_state_dict(load_from, strict=False)\n",
        "\n",
        "    def forward_x8(self, *args, forward_function=None):\n",
        "        def _transform(v, op):\n",
        "            if self.precision != 'single': v = v.float()\n",
        "\n",
        "            v2np = v.data.cpu().numpy()\n",
        "            if op == 'v':\n",
        "                tfnp = v2np[:, :, :, ::-1].copy()\n",
        "            elif op == 'h':\n",
        "                tfnp = v2np[:, :, ::-1, :].copy()\n",
        "            elif op == 't':\n",
        "                tfnp = v2np.transpose((0, 1, 3, 2)).copy()\n",
        "\n",
        "            ret = torch.Tensor(tfnp).to(self.device)\n",
        "            if self.precision == 'half': ret = ret.half()\n",
        "\n",
        "            return ret\n",
        "\n",
        "        list_x = []\n",
        "        for a in args:\n",
        "            x = [a]\n",
        "            for tf in 'v', 'h', 't': x.extend([_transform(_x, tf) for _x in x])\n",
        "\n",
        "            list_x.append(x)\n",
        "\n",
        "        list_y = []\n",
        "        for x in zip(*list_x):\n",
        "            y = forward_function(*x)\n",
        "            if not isinstance(y, list): y = [y]\n",
        "            if not list_y:\n",
        "                list_y = [[_y] for _y in y]\n",
        "            else:\n",
        "                for _list_y, _y in zip(list_y, y): _list_y.append(_y)\n",
        "\n",
        "        for _list_y in list_y:\n",
        "            for i in range(len(_list_y)):\n",
        "                if i > 3:\n",
        "                    _list_y[i] = _transform(_list_y[i], 't')\n",
        "                if i % 4 > 1:\n",
        "                    _list_y[i] = _transform(_list_y[i], 'h')\n",
        "                if (i % 4) % 2 == 1:\n",
        "                    _list_y[i] = _transform(_list_y[i], 'v')\n",
        "\n",
        "        y = [torch.cat(_y, dim=0).mean(dim=0, keepdim=True) for _y in list_y]\n",
        "        if len(y) == 1: y = y[0]\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def forward_chop(self, x, shave=12):\n",
        "        x.cpu()\n",
        "        batchsize = self.args.crop_batch_size\n",
        "        h, w = x.size()[-2:]\n",
        "        padsize = int(self.patch_size)\n",
        "        shave = int(self.patch_size/2)\n",
        "\n",
        "        scale = self.scale[self.idx_scale]\n",
        "\n",
        "        h_cut = (h-padsize)%(int(shave/2))\n",
        "        w_cut = (w-padsize)%(int(shave/2))\n",
        "\n",
        "        x_unfold = torch.nn.functional.unfold(x, padsize, stride=int(shave/2)).transpose(0,2).contiguous()\n",
        "\n",
        "        x_hw_cut = x[...,(h-padsize):,(w-padsize):]\n",
        "        y_hw_cut = self.model.forward(x_hw_cut.cuda()).cpu()\n",
        "\n",
        "        x_h_cut = x[...,(h-padsize):,:]\n",
        "        x_w_cut = x[...,:,(w-padsize):]\n",
        "        y_h_cut = self.cut_h(x_h_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "        y_w_cut = self.cut_w(x_w_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "        \n",
        "        x_h_top = x[...,:padsize,:]\n",
        "        x_w_top = x[...,:,:padsize]\n",
        "        y_h_top = self.cut_h(x_h_top, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "        y_w_top = self.cut_w(x_w_top, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "\n",
        "        x_unfold = x_unfold.view(x_unfold.size(0),-1,padsize,padsize)\n",
        "        y_unfold = []\n",
        "\n",
        "        x_range = x_unfold.size(0)//batchsize + (x_unfold.size(0)%batchsize !=0)\n",
        "        x_unfold.cuda()\n",
        "        for i in range(x_range):\n",
        "            y_unfold.append(P.data_parallel(self.model, x_unfold[i*batchsize:(i+1)*batchsize,...], range(self.n_GPUs)).cpu())\n",
        "        y_unfold = torch.cat(y_unfold,dim=0)\n",
        "\n",
        "        y = torch.nn.functional.fold(y_unfold.view(y_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut)*scale,(w-w_cut)*scale), padsize*scale, stride=int(shave/2*scale))\n",
        "        \n",
        "        y[...,:padsize*scale,:] = y_h_top\n",
        "        y[...,:,:padsize*scale] = y_w_top\n",
        "\n",
        "        y_unfold = y_unfold[...,int(shave/2*scale):padsize*scale-int(shave/2*scale),int(shave/2*scale):padsize*scale-int(shave/2*scale)].contiguous()\n",
        "        y_inter = torch.nn.functional.fold(y_unfold.view(y_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut-shave)*scale,(w-w_cut-shave)*scale), padsize*scale-shave*scale, stride=int(shave/2*scale))\n",
        "        \n",
        "        y_ones = torch.ones(y_inter.shape, dtype=y_inter.dtype)\n",
        "        divisor = torch.nn.functional.fold(torch.nn.functional.unfold(y_ones, padsize*scale-shave*scale, stride=int(shave/2*scale)),((h-h_cut-shave)*scale,(w-w_cut-shave)*scale), padsize*scale-shave*scale, stride=int(shave/2*scale))\n",
        "        \n",
        "        y_inter = y_inter/divisor\n",
        "\n",
        "        y[...,int(shave/2*scale):(h-h_cut)*scale-int(shave/2*scale),int(shave/2*scale):(w-w_cut)*scale-int(shave/2*scale)] = y_inter\n",
        "\n",
        "        y = torch.cat([y[...,:y.size(2)-int((padsize-h_cut)/2*scale),:],y_h_cut[...,int((padsize-h_cut)/2*scale+0.5):,:]],dim=2)\n",
        "        y_w_cat = torch.cat([y_w_cut[...,:y_w_cut.size(2)-int((padsize-h_cut)/2*scale),:],y_hw_cut[...,int((padsize-h_cut)/2*scale+0.5):,:]],dim=2)\n",
        "        y = torch.cat([y[...,:,:y.size(3)-int((padsize-w_cut)/2*scale)],y_w_cat[...,:,int((padsize-w_cut)/2*scale+0.5):]],dim=3)\n",
        "        return y.cuda()\n",
        "    \n",
        "    def cut_h(self, x_h_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize):\n",
        "        \n",
        "        x_h_cut_unfold = torch.nn.functional.unfold(x_h_cut, padsize, stride=int(shave/2)).transpose(0,2).contiguous()\n",
        "        \n",
        "        x_h_cut_unfold = x_h_cut_unfold.view(x_h_cut_unfold.size(0),-1,padsize,padsize)\n",
        "        x_range = x_h_cut_unfold.size(0)//batchsize + (x_h_cut_unfold.size(0)%batchsize !=0)\n",
        "        y_h_cut_unfold=[]\n",
        "        x_h_cut_unfold.cuda()\n",
        "        for i in range(x_range):\n",
        "            y_h_cut_unfold.append(P.data_parallel(self.model, x_h_cut_unfold[i*batchsize:(i+1)*batchsize,...], range(self.n_GPUs)).cpu())\n",
        "        y_h_cut_unfold = torch.cat(y_h_cut_unfold,dim=0)\n",
        "        \n",
        "        y_h_cut = torch.nn.functional.fold(y_h_cut_unfold.view(y_h_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),(padsize*scale,(w-w_cut)*scale), padsize*scale, stride=int(shave/2*scale))\n",
        "        y_h_cut_unfold = y_h_cut_unfold[...,:,int(shave/2*scale):padsize*scale-int(shave/2*scale)].contiguous()\n",
        "        y_h_cut_inter = torch.nn.functional.fold(y_h_cut_unfold.view(y_h_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),(padsize*scale,(w-w_cut-shave)*scale), (padsize*scale,padsize*scale-shave*scale), stride=int(shave/2*scale))\n",
        "        \n",
        "        y_ones = torch.ones(y_h_cut_inter.shape, dtype=y_h_cut_inter.dtype)\n",
        "        divisor = torch.nn.functional.fold(torch.nn.functional.unfold(y_ones ,(padsize*scale,padsize*scale-shave*scale), stride=int(shave/2*scale)),(padsize*scale,(w-w_cut-shave)*scale), (padsize*scale,padsize*scale-shave*scale), stride=int(shave/2*scale)) \n",
        "        y_h_cut_inter = y_h_cut_inter/divisor\n",
        "        \n",
        "        y_h_cut[...,:,int(shave/2*scale):(w-w_cut)*scale-int(shave/2*scale)] = y_h_cut_inter\n",
        "        return y_h_cut\n",
        "        \n",
        "    def cut_w(self, x_w_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize):\n",
        "        \n",
        "        x_w_cut_unfold = torch.nn.functional.unfold(x_w_cut, padsize, stride=int(shave/2)).transpose(0,2).contiguous()\n",
        "        \n",
        "        x_w_cut_unfold = x_w_cut_unfold.view(x_w_cut_unfold.size(0),-1,padsize,padsize)\n",
        "        x_range = x_w_cut_unfold.size(0)//batchsize + (x_w_cut_unfold.size(0)%batchsize !=0)\n",
        "        y_w_cut_unfold=[]\n",
        "        x_w_cut_unfold.cuda()\n",
        "        for i in range(x_range):\n",
        "            y_w_cut_unfold.append(P.data_parallel(self.model, x_w_cut_unfold[i*batchsize:(i+1)*batchsize,...], range(self.n_GPUs)).cpu())\n",
        "        y_w_cut_unfold = torch.cat(y_w_cut_unfold,dim=0)\n",
        "        \n",
        "        y_w_cut = torch.nn.functional.fold(y_w_cut_unfold.view(y_w_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut)*scale,padsize*scale), padsize*scale, stride=int(shave/2*scale))\n",
        "        y_w_cut_unfold = y_w_cut_unfold[...,int(shave/2*scale):padsize*scale-int(shave/2*scale),:].contiguous()\n",
        "        y_w_cut_inter = torch.nn.functional.fold(y_w_cut_unfold.view(y_w_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut-shave)*scale,padsize*scale), (padsize*scale-shave*scale,padsize*scale), stride=int(shave/2*scale))\n",
        "        \n",
        "        y_ones = torch.ones(y_w_cut_inter.shape, dtype=y_w_cut_inter.dtype)\n",
        "        divisor = torch.nn.functional.fold(torch.nn.functional.unfold(y_ones ,(padsize*scale-shave*scale,padsize*scale), stride=int(shave/2*scale)),((h-h_cut-shave)*scale,padsize*scale), (padsize*scale-shave*scale,padsize*scale), stride=int(shave/2*scale))\n",
        "        y_w_cut_inter = y_w_cut_inter/divisor\n",
        "\n",
        "        y_w_cut[...,int(shave/2*scale):(h-h_cut)*scale-int(shave/2*scale),:] = y_w_cut_inter\n",
        "        return y_w_cut\n",
        "'''     \n",
        "    def forward_chop_new(self, x, shave=12, batchsize = 64):\n",
        "        h, w = x.size()[-2:]\n",
        "        padsize = int(self.patch_size)\n",
        "        shave = int(self.patch_size/4)\n",
        "\n",
        "        scale = self.scale[self.idx_scale]\n",
        "\n",
        "        h_cut = (h-padsize)%(padsize-shave)\n",
        "        w_cut = (w-padsize)%(padsize-shave)\n",
        "\n",
        "        x_unfold = torch.nn.functional.unfold(x, padsize, stride=padsize-shave).transpose(0,2).contiguous()\n",
        "\n",
        "        x_hw_cut = x[...,(h-padsize):,(w-padsize):]\n",
        "        y_hw_cut = self.model.forward(x_hw_cut)\n",
        "\n",
        "        x_h_cut = x[...,(h-padsize):,:]\n",
        "        x_w_cut = x[...,:,(w-padsize):]\n",
        "        y_h_cut = self.cut_h_new(x_h_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "        y_w_cut = self.cut_w_new(x_w_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "\n",
        "        x_h_top = x[...,:padsize,:]\n",
        "        x_w_top = x[...,:,:padsize]\n",
        "        y_h_top = self.cut_h_new(x_h_top, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "        y_w_top = self.cut_w_new(x_w_top, h, w, h_cut, w_cut, padsize, shave, scale, batchsize)\n",
        "\n",
        "        x_unfold = x_unfold.view(x_unfold.size(0),-1,padsize,padsize)\n",
        "        y_unfold = []\n",
        "\n",
        "        x_range = x_unfold.size(0)//batchsize + (x_unfold.size(0)%batchsize !=0)\n",
        "        for i in range(x_range):\n",
        "            y_unfold.append(self.model.forward(x_unfold[i*batchsize:(i+1)*batchsize,...]))\n",
        "        y_unfold = torch.cat(y_unfold,dim=0)\n",
        "\n",
        "        y = torch.nn.functional.fold(y_unfold.view(y_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut)*scale,(w-w_cut)*scale), padsize*scale, stride=padsize*scale-shave*scale)\n",
        "\n",
        "        y[...,:padsize*scale,:] = y_h_top\n",
        "        y[...,:,:padsize*scale] = y_w_top\n",
        "\n",
        "        y_unfold = y_unfold[...,int(shave/2*scale):padsize*scale-int(shave/2*scale),int(shave/2*scale):padsize*scale-int(shave/2*scale)].contiguous()\n",
        "        y_inter = torch.nn.functional.fold(y_unfold.view(y_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut-shave)*scale,(w-w_cut-shave)*scale), padsize*scale-shave*scale, stride=padsize*scale-shave*scale)\n",
        "        y[...,int(shave/2*scale):(h-h_cut)*scale-int(shave/2*scale),int(shave/2*scale):(w-w_cut)*scale-int(shave/2*scale)] = y_inter\n",
        "\n",
        "        y = torch.cat([y[...,:y.size(2)-int((padsize-h_cut)/2*scale),:],y_h_cut[...,int((padsize-h_cut)/2*scale+0.5):,:]],dim=2)\n",
        "        y_w_cat = torch.cat([y_w_cut[...,:y_w_cut.size(2)-int((padsize-h_cut)/2*scale),:],y_hw_cut[...,int((padsize-h_cut)/2*scale+0.5):,:]],dim=2)\n",
        "        y = torch.cat([y[...,:,:y.size(3)-int((padsize-w_cut)/2*scale)],y_w_cat[...,:,int((padsize-w_cut)/2*scale+0.5):]],dim=3)\n",
        "\n",
        "        return y\n",
        "    \n",
        "    def cut_h_new(self, x_h_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize):\n",
        "        \n",
        "        x_h_cut_unfold = torch.nn.functional.unfold(x_h_cut, padsize, stride=padsize-shave).transpose(0,2).contiguous()\n",
        "        \n",
        "        x_h_cut_unfold = x_h_cut_unfold.view(x_h_cut_unfold.size(0),-1,padsize,padsize)\n",
        "        x_range = x_h_cut_unfold.size(0)//batchsize + (x_h_cut_unfold.size(0)%batchsize !=0)\n",
        "        y_h_cut_unfold=[]\n",
        "        for i in range(x_range):\n",
        "            y_h_cut_unfold.append(self.model.forward(x_h_cut_unfold[i*batchsize:(i+1)*batchsize,...]))\n",
        "        y_h_cut_unfold = torch.cat(y_h_cut_unfold,dim=0)\n",
        "        \n",
        "        y_h_cut = torch.nn.functional.fold(y_h_cut_unfold.view(y_h_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),(padsize*scale,(w-w_cut)*scale), padsize*scale, stride=padsize*scale-shave*scale)\n",
        "        y_h_cut_unfold = y_h_cut_unfold[...,:,int(shave/2*scale):padsize*scale-int(shave/2*scale)].contiguous()\n",
        "        y_h_cut_inter = torch.nn.functional.fold(y_h_cut_unfold.view(y_h_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),(padsize*scale,(w-w_cut-shave)*scale), (padsize*scale,padsize*scale-shave*scale), stride=padsize*scale-shave*scale)\n",
        "        y_h_cut[...,:,int(shave/2*scale):(w-w_cut)*scale-int(shave/2*scale)] = y_h_cut_inter\n",
        "        return y_h_cut\n",
        "        \n",
        "    def cut_w_new(self, x_w_cut, h, w, h_cut, w_cut, padsize, shave, scale, batchsize):\n",
        "        \n",
        "        x_w_cut_unfold = torch.nn.functional.unfold(x_w_cut, padsize, stride=padsize-shave).transpose(0,2).contiguous()\n",
        "        \n",
        "        x_w_cut_unfold = x_w_cut_unfold.view(x_w_cut_unfold.size(0),-1,padsize,padsize)\n",
        "        x_range = x_w_cut_unfold.size(0)//batchsize + (x_w_cut_unfold.size(0)%batchsize !=0)\n",
        "        y_w_cut_unfold=[]\n",
        "        for i in range(x_range):\n",
        "            y_w_cut_unfold.append(self.model.forward(x_w_cut_unfold[i*batchsize:(i+1)*batchsize,...]))\n",
        "        y_w_cut_unfold = torch.cat(y_w_cut_unfold,dim=0)\n",
        "        \n",
        "        y_w_cut = torch.nn.functional.fold(y_w_cut_unfold.view(y_w_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut)*scale,padsize*scale), padsize*scale, stride=padsize*scale-shave*scale)\n",
        "        y_w_cut_unfold = y_w_cut_unfold[...,int(shave/2*scale):padsize*scale-int(shave/2*scale),:].contiguous()\n",
        "        y_w_cut_inter = torch.nn.functional.fold(y_w_cut_unfold.view(y_w_cut_unfold.size(0),-1,1).transpose(0,2).contiguous(),((h-h_cut-shave)*scale,padsize*scale), (padsize*scale-shave*scale,padsize*scale), stride=padsize*scale-shave*scale)\n",
        "        y_w_cut[...,int(shave/2*scale):(h-h_cut)*scale-int(shave/2*scale),:] = y_w_cut_inter\n",
        "        return y_w_cut\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1atHQWW4blIl"
      },
      "source": [
        "common.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQQ0sS9UbncN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb081979-7a53-41b0-f80a-61d01972bd18"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile modelcommon.py\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(\n",
        "        in_channels, out_channels, kernel_size,\n",
        "        padding=(kernel_size//2), bias=bias)\n",
        "\n",
        "class MeanShift(nn.Conv2d):\n",
        "    def __init__(\n",
        "        self, rgb_range,\n",
        "        rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
        "\n",
        "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
        "        std = torch.Tensor(rgb_std)\n",
        "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
        "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
        "        for p in self.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "class BasicBlock(nn.Sequential):\n",
        "    def __init__(\n",
        "        self, conv, in_channels, out_channels, kernel_size, stride=1, bias=False,\n",
        "        bn=True, act=nn.ReLU(True)):\n",
        "\n",
        "        m = [conv(in_channels, out_channels, kernel_size, bias=bias)]\n",
        "        if bn:\n",
        "            m.append(nn.BatchNorm2d(out_channels))\n",
        "        if act is not None:\n",
        "            m.append(act)\n",
        "\n",
        "        super(BasicBlock, self).__init__(*m)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, conv, n_feats, kernel_size,\n",
        "        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
        "\n",
        "        super(ResBlock, self).__init__()\n",
        "        m = []\n",
        "        for i in range(2):\n",
        "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
        "            if bn:\n",
        "                m.append(nn.BatchNorm2d(n_feats))\n",
        "            if i == 0:\n",
        "                m.append(act)\n",
        "\n",
        "        self.body = nn.Sequential(*m)\n",
        "        self.res_scale = res_scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x).mul(self.res_scale)\n",
        "        res += x\n",
        "\n",
        "        return res\n",
        "\n",
        "class Upsampler(nn.Sequential):\n",
        "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
        "\n",
        "        m = []\n",
        "        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\n",
        "            for _ in range(int(math.log(scale, 2))):\n",
        "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
        "                m.append(nn.PixelShuffle(2))\n",
        "                if bn:\n",
        "                    m.append(nn.BatchNorm2d(n_feats))\n",
        "                if act == 'relu':\n",
        "                    m.append(nn.ReLU(True))\n",
        "                elif act == 'prelu':\n",
        "                    m.append(nn.PReLU(n_feats))\n",
        "\n",
        "        elif scale == 3:\n",
        "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
        "            m.append(nn.PixelShuffle(3))\n",
        "            if bn:\n",
        "                m.append(nn.BatchNorm2d(n_feats))\n",
        "            if act == 'relu':\n",
        "                m.append(nn.ReLU(True))\n",
        "            elif act == 'prelu':\n",
        "                m.append(nn.PReLU(n_feats))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        super(Upsampler, self).__init__(*m)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting modelcommon.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw-rp8aFbun1"
      },
      "source": [
        "ipt.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYutFj3Gbx9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b10cc0-bdeb-41cb-fea9-b31b3394ecf1"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
        "%%writefile ipt.py\n",
        "execfile('modelcommon.py')\n",
        "import modelcommon\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, Tensor\n",
        "from einops import rearrange\n",
        "import copy\n",
        "\n",
        "def make_model(args, parent=False):\n",
        "    return ipt(args)\n",
        "\n",
        "class ipt(nn.Module):\n",
        "    def __init__(self, args, conv=modelcommon.default_conv):\n",
        "        super(ipt, self).__init__()\n",
        "        \n",
        "        self.scale_idx = 0\n",
        "        \n",
        "        self.args = args\n",
        "        \n",
        "        n_feats = args.n_feats\n",
        "        kernel_size = 3 \n",
        "        act = nn.ReLU(True)\n",
        "\n",
        "        self.sub_mean = modelcommon.MeanShift(args.rgb_range)\n",
        "        self.add_mean = modelcommon.MeanShift(args.rgb_range, sign=1)\n",
        "\n",
        "        self.head = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                conv(args.n_colors, n_feats, kernel_size),\n",
        "                modelcommon.ResBlock(conv, n_feats, 5, act=act),\n",
        "                modelcommon.ResBlock(conv, n_feats, 5, act=act)\n",
        "            ) for _ in args.scale\n",
        "        ])\n",
        "\n",
        "        self.body = VisionTransformer(img_dim=args.patch_size, patch_dim=args.patch_dim, num_channels=n_feats, embedding_dim=n_feats*args.patch_dim*args.patch_dim, num_heads=args.num_heads, num_layers=args.num_layers, hidden_dim=n_feats*args.patch_dim*args.patch_dim*4, num_queries = args.num_queries, dropout_rate=args.dropout_rate, mlp=args.no_mlp ,pos_every=args.pos_every,no_pos=args.no_pos,no_norm=args.no_norm)\n",
        "\n",
        "        self.tail = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                modelcommon.Upsampler(conv, s, n_feats, act=False),\n",
        "                conv(n_feats, args.n_colors, kernel_size)\n",
        "            ) for s in args.scale\n",
        "        ])\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sub_mean(x)\n",
        "        x = self.head[self.scale_idx](x)\n",
        "\n",
        "        res = self.body(x,self.scale_idx)\n",
        "        res += x\n",
        "\n",
        "        x = self.tail[self.scale_idx](res)\n",
        "        x = self.add_mean(x)\n",
        "\n",
        "        return x \n",
        "\n",
        "    def set_scale(self, scale_idx):\n",
        "        self.scale_idx = scale_idx\n",
        "        \n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_dim,\n",
        "        patch_dim,\n",
        "        num_channels,\n",
        "        embedding_dim,\n",
        "        num_heads,\n",
        "        num_layers,\n",
        "        hidden_dim,\n",
        "        num_queries,\n",
        "        positional_encoding_type=\"learned\",\n",
        "        dropout_rate=0,\n",
        "        no_norm=False,\n",
        "        mlp=False,\n",
        "        pos_every=False,\n",
        "        no_pos = False\n",
        "    ):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "\n",
        "        assert embedding_dim % num_heads == 0\n",
        "        assert img_dim % patch_dim == 0\n",
        "        self.no_norm = no_norm\n",
        "        self.mlp = mlp\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.patch_dim = patch_dim\n",
        "        self.num_channels = num_channels\n",
        "        \n",
        "        self.img_dim = img_dim\n",
        "        self.pos_every = pos_every\n",
        "        self.num_patches = int((img_dim // patch_dim) ** 2)\n",
        "        self.seq_length = self.num_patches\n",
        "        self.flatten_dim = patch_dim * patch_dim * num_channels\n",
        "        \n",
        "        self.out_dim = patch_dim * patch_dim * num_channels\n",
        "        \n",
        "        self.no_pos = no_pos\n",
        "        \n",
        "        if self.mlp==False:\n",
        "            self.linear_encoding = nn.Linear(self.flatten_dim, embedding_dim)\n",
        "            self.mlp_head = nn.Sequential(\n",
        "                nn.Linear(embedding_dim, hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, self.out_dim),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            )\n",
        "        \n",
        "            self.query_embed = nn.Embedding(num_queries, embedding_dim * self.seq_length)\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout_rate, self.no_norm)\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_layers)\n",
        "        \n",
        "        decoder_layer = TransformerDecoderLayer(embedding_dim, num_heads, hidden_dim, dropout_rate, self.no_norm)\n",
        "        self.decoder = TransformerDecoder(decoder_layer, num_layers)\n",
        "        \n",
        "        if not self.no_pos:\n",
        "            self.position_encoding = LearnedPositionalEncoding(\n",
        "                    self.seq_length, self.embedding_dim, self.seq_length\n",
        "                )\n",
        "            \n",
        "        self.dropout_layer1 = nn.Dropout(dropout_rate)\n",
        "        \n",
        "        if no_norm:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.normal_(m.weight, std = 1/m.weight.size(1))\n",
        "\n",
        "    def forward(self, x, query_idx, con=False):\n",
        "\n",
        "        x = torch.nn.functional.unfold(x,self.patch_dim,stride=self.patch_dim).transpose(1,2).transpose(0,1).contiguous()\n",
        "               \n",
        "        if self.mlp==False:\n",
        "            x = self.dropout_layer1(self.linear_encoding(x)) + x\n",
        "\n",
        "            query_embed = self.query_embed.weight[query_idx].view(-1,1,self.embedding_dim).repeat(1,x.size(1), 1)\n",
        "        else:\n",
        "            query_embed = None\n",
        "\n",
        "        \n",
        "        if not self.no_pos:\n",
        "            pos = self.position_encoding(x).transpose(0,1)\n",
        "\n",
        "        if self.pos_every:\n",
        "            x = self.encoder(x, pos=pos)\n",
        "            x = self.decoder(x, x, pos=pos, query_pos=query_embed)\n",
        "        elif self.no_pos:\n",
        "            x = self.encoder(x)\n",
        "            x = self.decoder(x, x, query_pos=query_embed)\n",
        "        else:\n",
        "            x = self.encoder(x+pos)\n",
        "            x = self.decoder(x, x, query_pos=query_embed)\n",
        "        \n",
        "        \n",
        "        if self.mlp==False:\n",
        "            x = self.mlp_head(x) + x\n",
        "        \n",
        "        x = x.transpose(0,1).contiguous().view(x.size(1), -1, self.flatten_dim)\n",
        "        \n",
        "        if con:\n",
        "            con_x = x\n",
        "            x = torch.nn.functional.fold(x.transpose(1,2).contiguous(),int(self.img_dim),self.patch_dim,stride=self.patch_dim)\n",
        "            return x, con_x\n",
        "        \n",
        "        x = torch.nn.functional.fold(x.transpose(1,2).contiguous(),int(self.img_dim),self.patch_dim,stride=self.patch_dim)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class LearnedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, max_position_embeddings, embedding_dim, seq_length):\n",
        "        super(LearnedPositionalEncoding, self).__init__()\n",
        "        self.pe = nn.Embedding(max_position_embeddings, embedding_dim)\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.register_buffer(\n",
        "            \"position_ids\", torch.arange(self.seq_length).expand((1, -1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x, position_ids=None):\n",
        "        if position_ids is None:\n",
        "            position_ids = self.position_ids[:, : self.seq_length]\n",
        "\n",
        "        position_embeddings = self.pe(position_ids)\n",
        "        return position_embeddings\n",
        "    \n",
        "class TransformerEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, src, pos = None):\n",
        "        output = src\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer(output, pos=pos)\n",
        "\n",
        "        return output\n",
        "    \n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, no_norm = False,\n",
        "                 activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, bias=False)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        \n",
        "        self.norm1 = nn.LayerNorm(d_model) if not no_norm else nn.Identity()\n",
        "        self.norm2 = nn.LayerNorm(d_model) if not no_norm else nn.Identity()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = _get_activation_fn(activation)\n",
        "        \n",
        "        nn.init.kaiming_uniform_(self.self_attn.in_proj_weight, a=math.sqrt(5))\n",
        "\n",
        "    def with_pos_embed(self, tensor, pos):\n",
        "        return tensor if pos is None else tensor + pos\n",
        "    \n",
        "    def forward(self, src, pos = None):\n",
        "        src2 = self.norm1(src)\n",
        "        q = k = self.with_pos_embed(src2, pos)\n",
        "        src2 = self.self_attn(q, k, src2)\n",
        "        src = src + self.dropout1(src2[0])\n",
        "        src2 = self.norm2(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        return src\n",
        "\n",
        "    \n",
        "class TransformerDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, decoder_layer, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(decoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, tgt, memory, pos = None, query_pos = None):\n",
        "        output = tgt\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            output = layer(output, memory, pos=pos, query_pos=query_pos)\n",
        "\n",
        "        return output\n",
        "\n",
        "    \n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, no_norm = False,\n",
        "                 activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, bias=False)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, bias=False)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model) if not no_norm else nn.Identity()\n",
        "        self.norm2 = nn.LayerNorm(d_model) if not no_norm else nn.Identity()\n",
        "        self.norm3 = nn.LayerNorm(d_model) if not no_norm else nn.Identity()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = _get_activation_fn(activation)\n",
        "\n",
        "    def with_pos_embed(self, tensor, pos):\n",
        "        return tensor if pos is None else tensor + pos\n",
        "\n",
        "    def forward(self, tgt, memory, pos = None, query_pos = None):\n",
        "        tgt2 = self.norm1(tgt)\n",
        "        q = k = self.with_pos_embed(tgt2, query_pos)\n",
        "        tgt2 = self.self_attn(q, k, value=tgt2)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt2 = self.norm2(tgt)\n",
        "        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),\n",
        "                                   key=self.with_pos_embed(memory, pos),\n",
        "                                   value=memory)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt2 = self.norm3(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        return tgt\n",
        "\n",
        "\n",
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    \"\"\"Return an activation function given a string\"\"\"\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    if activation == \"gelu\":\n",
        "        return F.gelu\n",
        "    if activation == \"glu\":\n",
        "        return F.glu\n",
        "    raise RuntimeError(F\"activation should be relu/gelu, not {activation}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ipt.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqIcuWFecItH"
      },
      "source": [
        "#DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bDvcbwxcKMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc0f004-f486-4f3e-d95c-54d3225544e9"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile dataloader.py\n",
        "import threading\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.multiprocessing as multiprocessing\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torch.utils.data import RandomSampler\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import _utils\n",
        "#from torch.utils.data.dataloader import _DataLoaderIter\n",
        "from torch.utils.data.dataloader import _BaseDataLoaderIter\n",
        "from torch.utils.data._utils import collate\n",
        "from torch.utils.data._utils import signal_handling\n",
        "from torch.utils.data._utils import MP_STATUS_CHECK_INTERVAL\n",
        "from torch.utils.data._utils import ExceptionWrapper\n",
        "from torch.utils.data._utils import IS_WINDOWS\n",
        "from torch.utils.data._utils.worker import ManagerWatchdog\n",
        "\n",
        "from torch._six import queue\n",
        "\n",
        "def _ms_loop(dataset, index_queue, data_queue, done_event, collate_fn, scale, seed, init_fn, worker_id):\n",
        "    try:\n",
        "        collate._use_shared_memory = True\n",
        "        signal_handling._set_worker_signal_handlers()\n",
        "\n",
        "        torch.set_num_threads(1)\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        data_queue.cancel_join_thread()\n",
        "\n",
        "        if init_fn is not None:\n",
        "            init_fn(worker_id)\n",
        "\n",
        "        watchdog = ManagerWatchdog()\n",
        "\n",
        "        while watchdog.is_alive():\n",
        "            try:\n",
        "                r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
        "            except queue.Empty:\n",
        "                continue\n",
        "\n",
        "            if r is None:\n",
        "                assert done_event.is_set()\n",
        "                return\n",
        "            elif done_event.is_set():\n",
        "                continue\n",
        "\n",
        "            idx, batch_indices = r\n",
        "            try:\n",
        "                idx_scale = 0\n",
        "                if len(scale) > 1 and dataset.train:\n",
        "                    idx_scale = random.randrange(0, len(scale))\n",
        "                    dataset.set_scale(idx_scale)\n",
        "\n",
        "                samples = collate_fn([dataset[i] for i in batch_indices])\n",
        "                samples.append(idx_scale)\n",
        "            except Exception:\n",
        "                data_queue.put((idx, ExceptionWrapper(sys.exc_info())))\n",
        "            else:\n",
        "                data_queue.put((idx, samples))\n",
        "                del samples\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "class _MSDataLoaderIter(_BaseDataLoaderIter):\n",
        "\n",
        "    def __init__(self, loader):\n",
        "        self.dataset = loader.dataset\n",
        "        self.scale = loader.scale\n",
        "        self.collate_fn = loader.collate_fn\n",
        "        self.batch_sampler = loader.batch_sampler\n",
        "        self.num_workers = loader.num_workers\n",
        "        self.pin_memory = loader.pin_memory and torch.cuda.is_available()\n",
        "        self.timeout = loader.timeout\n",
        "\n",
        "        self.sample_iter = iter(self.batch_sampler)\n",
        "\n",
        "        base_seed = torch.LongTensor(1).random_().item()\n",
        "\n",
        "        if self.num_workers > 0:\n",
        "            self.worker_init_fn = loader.worker_init_fn\n",
        "            self.worker_queue_idx = 0\n",
        "            self.worker_result_queue = multiprocessing.Queue()\n",
        "            self.batches_outstanding = 0\n",
        "            self.worker_pids_set = False\n",
        "            self.shutdown = False\n",
        "            self.send_idx = 0\n",
        "            self.rcvd_idx = 0\n",
        "            self.reorder_dict = {}\n",
        "            self.done_event = multiprocessing.Event()\n",
        "\n",
        "            base_seed = torch.LongTensor(1).random_()[0]\n",
        "\n",
        "            self.index_queues = []\n",
        "            self.workers = []\n",
        "            for i in range(self.num_workers):\n",
        "                index_queue = multiprocessing.Queue()\n",
        "                index_queue.cancel_join_thread()\n",
        "                w = multiprocessing.Process(\n",
        "                    target=_ms_loop,\n",
        "                    args=(\n",
        "                        self.dataset,\n",
        "                        index_queue,\n",
        "                        self.worker_result_queue,\n",
        "                        self.done_event,\n",
        "                        self.collate_fn,\n",
        "                        self.scale,\n",
        "                        base_seed + i,\n",
        "                        self.worker_init_fn,\n",
        "                        i\n",
        "                    )\n",
        "                )\n",
        "                w.daemon = True\n",
        "                w.start()\n",
        "                self.index_queues.append(index_queue)\n",
        "                self.workers.append(w)\n",
        "\n",
        "            if self.pin_memory:\n",
        "                self.data_queue = queue.Queue()\n",
        "                pin_memory_thread = threading.Thread(\n",
        "                    target=_utils.pin_memory._pin_memory_loop,\n",
        "                    args=(\n",
        "                        self.worker_result_queue,\n",
        "                        self.data_queue,\n",
        "                        torch.cuda.current_device(),\n",
        "                        self.done_event\n",
        "                    )\n",
        "                )\n",
        "                pin_memory_thread.daemon = True\n",
        "                pin_memory_thread.start()\n",
        "                self.pin_memory_thread = pin_memory_thread\n",
        "            else:\n",
        "                self.data_queue = self.worker_result_queue\n",
        "\n",
        "            _utils.signal_handling._set_worker_pids(\n",
        "                id(self), tuple(w.pid for w in self.workers)\n",
        "            )\n",
        "            _utils.signal_handling._set_SIGCHLD_handler()\n",
        "            self.worker_pids_set = True\n",
        "\n",
        "            for _ in range(2 * self.num_workers):\n",
        "                self._put_indices()\n",
        "\n",
        "\n",
        "class MSDataLoader(DataLoader):\n",
        "\n",
        "    def __init__(self, cfg, *args, **kwargs):\n",
        "        super(MSDataLoader, self).__init__(\n",
        "            *args, **kwargs, num_workers=cfg.n_threads\n",
        "        )\n",
        "        self.scale = cfg.scale\n",
        "\n",
        "    def __iter__(self):\n",
        "        return _MSDataLoaderIter(self)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataloader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0GsZd3khtu_"
      },
      "source": [
        "#UTILITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuCRnE9XhtdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932ff258-a003-4174-ff19-a3d3777ae4ec"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile utility.py\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import datetime\n",
        "from multiprocessing import Process\n",
        "from multiprocessing import Queue\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "\n",
        "class timer():\n",
        "    def __init__(self):\n",
        "        self.acc = 0\n",
        "        self.tic()\n",
        "\n",
        "    def tic(self):\n",
        "        self.t0 = time.time()\n",
        "\n",
        "    def toc(self, restart=False):\n",
        "        diff = time.time() - self.t0\n",
        "        if restart: self.t0 = time.time()\n",
        "        return diff\n",
        "\n",
        "    def hold(self):\n",
        "        self.acc += self.toc()\n",
        "\n",
        "    def release(self):\n",
        "        ret = self.acc\n",
        "        self.acc = 0\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def reset(self):\n",
        "        self.acc = 0\n",
        "\n",
        "class checkpoint():\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.ok = True\n",
        "        self.log = torch.Tensor()\n",
        "        now = datetime.datetime.now().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "\n",
        "        if not args.load:\n",
        "            if not args.save:\n",
        "                args.save = now\n",
        "            self.dir = os.path.join('..', 'experiment', args.save)\n",
        "        else:\n",
        "            self.dir = os.path.join('..', 'experiment', args.load)\n",
        "            if os.path.exists(self.dir):\n",
        "                self.log = torch.load(self.get_path('psnr_log.pt'))\n",
        "                print('Continue from epoch {}...'.format(len(self.log)))\n",
        "            else:\n",
        "                args.load = ''\n",
        "\n",
        "        if args.reset:\n",
        "            os.system('rm -rf ' + self.dir)\n",
        "            args.load = ''\n",
        "\n",
        "        os.makedirs(self.dir, exist_ok=True)\n",
        "        os.makedirs(self.get_path('model'), exist_ok=True)\n",
        "        for d in args.data_test:\n",
        "            os.makedirs(self.get_path('results-{}'.format(d)), exist_ok=True)\n",
        "\n",
        "        open_type = 'a' if os.path.exists(self.get_path('log.txt'))else 'w'\n",
        "        self.log_file = open(self.get_path('log.txt'), open_type)\n",
        "        with open(self.get_path('config.txt'), open_type) as f:\n",
        "            f.write(now + '\\n\\n')\n",
        "            for arg in vars(args):\n",
        "                f.write('{}: {}\\n'.format(arg, getattr(args, arg)))\n",
        "            f.write('\\n')\n",
        "\n",
        "        self.n_processes = 8\n",
        "\n",
        "    def get_path(self, *subdir):\n",
        "        return os.path.join(self.dir, *subdir)\n",
        "\n",
        "    def save(self, trainer, epoch, is_best=False):\n",
        "        trainer.model.save(self.get_path('model'), epoch, is_best=is_best)\n",
        "        trainer.loss.save(self.dir)\n",
        "        trainer.loss.plot_loss(self.dir, epoch)\n",
        "\n",
        "        self.plot_psnr(epoch)\n",
        "        trainer.optimizer.save(self.dir)\n",
        "        torch.save(self.log, self.get_path('psnr_log.pt'))\n",
        "\n",
        "    def add_log(self, log):\n",
        "        self.log = torch.cat([self.log, log])\n",
        "\n",
        "    def write_log(self, log, refresh=False):\n",
        "        print(log)\n",
        "        self.log_file.write(log + '\\n')\n",
        "        if refresh:\n",
        "            self.log_file.close()\n",
        "            self.log_file = open(self.get_path('log.txt'), 'a')\n",
        "\n",
        "    def done(self):\n",
        "        self.log_file.close()\n",
        "\n",
        "    def plot_psnr(self, epoch):\n",
        "        axis = np.linspace(1, epoch, epoch)\n",
        "        for idx_data, d in enumerate(self.args.data_test):\n",
        "            label = 'SR on {}'.format(d)\n",
        "            fig = plt.figure()\n",
        "            plt.title(label)\n",
        "            for idx_scale, scale in enumerate(self.args.scale):\n",
        "                plt.plot(\n",
        "                    axis,\n",
        "                    self.log[:, idx_data, idx_scale].numpy(),\n",
        "                    label='Scale {}'.format(scale)\n",
        "                )\n",
        "            plt.legend()\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('PSNR')\n",
        "            plt.grid(True)\n",
        "            plt.savefig(self.get_path('test_{}.pdf'.format(d)))\n",
        "            plt.close(fig)\n",
        "\n",
        "    def begin_background(self):\n",
        "        self.queue = Queue()\n",
        "\n",
        "        def bg_target(queue):\n",
        "            while True:\n",
        "                if not queue.empty():\n",
        "                    filename, tensor = queue.get()\n",
        "                    if filename is None: break\n",
        "                    imageio.imwrite(filename, tensor.numpy())\n",
        "        \n",
        "        self.process = [\n",
        "            Process(target=bg_target, args=(self.queue,)) \\\n",
        "            for _ in range(self.n_processes)\n",
        "        ]\n",
        "        \n",
        "        for p in self.process: p.start()\n",
        "\n",
        "    def end_background(self):\n",
        "        for _ in range(self.n_processes): self.queue.put((None, None))\n",
        "        while not self.queue.empty(): time.sleep(1)\n",
        "        for p in self.process: p.join()\n",
        "\n",
        "    def save_results(self, dataset, filename, save_list, scale):\n",
        "        if self.args.save_results:\n",
        "            filename = self.get_path(\n",
        "                'results-{}'.format(dataset.dataset.name),\n",
        "                '{}_x{}_'.format(filename, scale)\n",
        "            )\n",
        "\n",
        "            postfix = ('SR', 'LR', 'HR')\n",
        "            for v, p in zip(save_list, postfix):\n",
        "                normalized = v[0].mul(255 / self.args.rgb_range)\n",
        "                tensor_cpu = normalized.byte().permute(1, 2, 0).cpu()\n",
        "                self.queue.put(('{}{}.png'.format(filename, p), tensor_cpu))\n",
        "\n",
        "def quantize(img, rgb_range):\n",
        "    pixel_range = 255 / rgb_range\n",
        "    return img.mul(pixel_range).clamp(0, 255).round().div(pixel_range)\n",
        "\n",
        "def calc_psnr(sr, hr, scale, rgb_range, cal_type='y'):\n",
        "    if hr.nelement() == 1: return 0\n",
        "\n",
        "    diff = (sr - hr) / rgb_range\n",
        "    \n",
        "    if cal_type=='y':\n",
        "        gray_coeffs = [65.738, 129.057, 25.064]\n",
        "        convert = diff.new_tensor(gray_coeffs).view(1, 3, 1, 1) / 256\n",
        "        diff = diff.mul(convert).sum(dim=1)\n",
        "    \n",
        "    if scale == 1:\n",
        "        valid = diff\n",
        "    else:\n",
        "        valid = diff[..., scale:-scale, scale:-scale]\n",
        "    mse = valid.pow(2).mean()\n",
        "\n",
        "    return -10 * math.log10(mse)\n",
        "\n",
        "def make_optimizer(args, target):\n",
        "    '''\n",
        "        make optimizer and scheduler together\n",
        "    '''\n",
        "    # optimizer\n",
        "    trainable = filter(lambda x: x.requires_grad, target.parameters())\n",
        "    kwargs_optimizer = {'lr': args.lr, 'weight_decay': args.weight_decay}\n",
        "\n",
        "    if args.optimizer == 'SGD':\n",
        "        optimizer_class = optim.SGD\n",
        "        kwargs_optimizer['momentum'] = args.momentum\n",
        "    elif args.optimizer == 'ADAM':\n",
        "        optimizer_class = optim.Adam\n",
        "        kwargs_optimizer['betas'] = args.betas\n",
        "        kwargs_optimizer['eps'] = args.epsilon\n",
        "    elif args.optimizer == 'RMSprop':\n",
        "        optimizer_class = optim.RMSprop\n",
        "        kwargs_optimizer['eps'] = args.epsilon\n",
        "\n",
        "    # scheduler\n",
        "    milestones = list(map(lambda x: int(x), args.decay.split('-')))\n",
        "    kwargs_scheduler = {'milestones': milestones, 'gamma': args.gamma}\n",
        "    scheduler_class = lrs.MultiStepLR\n",
        "\n",
        "    class CustomOptimizer(optimizer_class):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            super(CustomOptimizer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        def _register_scheduler(self, scheduler_class, **kwargs):\n",
        "            self.scheduler = scheduler_class(self, **kwargs)\n",
        "\n",
        "        def save(self, save_dir):\n",
        "            torch.save(self.state_dict(), self.get_dir(save_dir))\n",
        "\n",
        "        def load(self, load_dir, epoch=1):\n",
        "            self.load_state_dict(torch.load(self.get_dir(load_dir)))\n",
        "            if epoch > 1:\n",
        "                for _ in range(epoch): self.scheduler.step()\n",
        "\n",
        "        def get_dir(self, dir_path):\n",
        "            return os.path.join(dir_path, 'optimizer.pt')\n",
        "\n",
        "        def schedule(self):\n",
        "            self.scheduler.step()\n",
        "\n",
        "        def get_lr(self):\n",
        "            return self.scheduler.get_lr()[0]\n",
        "\n",
        "        def get_last_epoch(self):\n",
        "            return self.scheduler.last_epoch\n",
        "    \n",
        "    optimizer = CustomOptimizer(trainable, **kwargs_optimizer)\n",
        "    optimizer._register_scheduler(scheduler_class, **kwargs_scheduler)\n",
        "    return optimizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utility.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRBKQvd_hfmK"
      },
      "source": [
        "#TRAINER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAcmQx7fhf6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d263fe62-d98b-4ff7-ac29-dfc38954a663"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "%%writefile trainer.py\n",
        "execfile('utility.py')\n",
        "\n",
        "import utility\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, args, loader, my_model, my_loss, ckp):\n",
        "        self.args = args\n",
        "        self.scale = args.scale\n",
        "\n",
        "        self.ckp = ckp\n",
        "        self.loader_train = loader.loader_train\n",
        "        self.loader_test = loader.loader_test\n",
        "        self.model = my_model\n",
        "        self.loss = my_loss\n",
        "        self.optimizer = utility.make_optimizer(args, self.model)\n",
        "        if self.args.load != '':\n",
        "            self.optimizer.load(ckp.dir, epoch=len(ckp.log))\n",
        "\n",
        "        self.error_last = 1e8\n",
        "\n",
        "    def test(self):\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "        epoch = self.optimizer.get_last_epoch()\n",
        "        self.ckp.write_log('\\nEvaluation:')\n",
        "        self.ckp.add_log(\n",
        "            torch.zeros(1, len(self.loader_test), len(self.scale))\n",
        "        )\n",
        "        self.model.eval()\n",
        "        timer_test = utility.timer()\n",
        "        if self.args.save_results: self.ckp.begin_background()\n",
        "        for idx_data, d in enumerate(self.loader_test):\n",
        "            i = 0\n",
        "            for idx_scale, scale in enumerate(self.scale):\n",
        "                d.dataset.set_scale(idx_scale)\n",
        "                if self.args.derain:\n",
        "                    for norain, rain, filename in tqdm(d, ncols=80):\n",
        "                        norain,rain = self.prepare(norain, rain)\n",
        "                        sr = self.model(rain, idx_scale)\n",
        "                        sr = utility.quantize(sr, self.args.rgb_range)\n",
        "                        \n",
        "                        save_list = [sr]\n",
        "                        self.ckp.log[-1, idx_data, idx_scale] += utility.calc_psnr(\n",
        "                            sr, norain, scale, self.args.rgb_range\n",
        "                        ) \n",
        "                        if self.args.save_results:\n",
        "                            self.ckp.save_results(d, filename[0], save_list, 1)\n",
        "                    self.ckp.log[-1, idx_data, idx_scale] /= len(d)\n",
        "                    best = self.ckp.log.max(0)\n",
        "                    self.ckp.write_log(\n",
        "                        '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
        "                            d.dataset.name,\n",
        "                            scale,\n",
        "                            self.ckp.log[-1, idx_data, idx_scale],\n",
        "                            best[0][idx_data, idx_scale],\n",
        "                            best[1][idx_data, idx_scale] + 1\n",
        "                        )\n",
        "                    )\n",
        "                    isderain = 0\n",
        "                elif self.args.denoise:\n",
        "                    for hr, _,filename in tqdm(d, ncols=80):\n",
        "                        hr = self.prepare(hr)[0]\n",
        "                        noisy_level = self.args.sigma\n",
        "                        noise = torch.randn(hr.size()).mul_(noisy_level).cuda()\n",
        "                        nois_hr = (noise+hr).clamp(0,255)\n",
        "                        sr = self.model(nois_hr, idx_scale)\n",
        "                        sr = utility.quantize(sr, self.args.rgb_range)\n",
        "\n",
        "                        save_list = [sr, nois_hr, hr]\n",
        "                        self.ckp.log[-1, idx_data, idx_scale] += utility.calc_psnr(\n",
        "                            sr, hr, scale, self.args.rgb_range\n",
        "                        )\n",
        "                        if self.args.save_results:\n",
        "                            self.ckp.save_results(d, filename[0], save_list, 50)\n",
        "                            print (d,filename[0],save_list)\n",
        "                    self.ckp.log[-1, idx_data, idx_scale] /= len(d)\n",
        "                    best = self.ckp.log.max(0)\n",
        "                    self.ckp.write_log(\n",
        "                        '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
        "                            d.dataset.name,\n",
        "                            scale,\n",
        "                            self.ckp.log[-1, idx_data, idx_scale],\n",
        "                            best[0][idx_data, idx_scale],\n",
        "                            best[1][idx_data, idx_scale] + 1\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    for lr, hr, filename in tqdm(d, ncols=80):\n",
        "                        lr, hr = self.prepare(lr, hr)\n",
        "                        sr = self.model(lr, idx_scale)\n",
        "                        sr = utility.quantize(sr, self.args.rgb_range)\n",
        "\n",
        "                        save_list = [sr]\n",
        "                        self.ckp.log[-1, idx_data, idx_scale] += utility.calc_psnr(\n",
        "                            sr, hr, scale, self.args.rgb_range\n",
        "                        )\n",
        "                        #import pdb\n",
        "                        #pdb.set_trace()\n",
        "                        if self.args.save_gt:\n",
        "                            save_list.extend([lr, hr])\n",
        "\n",
        "                        if self.args.save_results:\n",
        "                            self.ckp.save_results(d, filename[0], save_list, scale)\n",
        "                        i = i+1\n",
        "                    self.ckp.log[-1, idx_data, idx_scale] /= len(d)\n",
        "                    best = self.ckp.log.max(0)\n",
        "                    self.ckp.write_log(\n",
        "                        '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
        "                            d.dataset.name,\n",
        "                            scale,\n",
        "                            self.ckp.log[-1, idx_data, idx_scale],\n",
        "                            best[0][idx_data, idx_scale],\n",
        "                            best[1][idx_data, idx_scale] + 1\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        self.ckp.write_log('Forward: {:.2f}s\\n'.format(timer_test.toc()))\n",
        "        self.ckp.write_log('Saving...')\n",
        "\n",
        "        if self.args.save_results:\n",
        "            self.ckp.end_background()\n",
        "\n",
        "        self.ckp.write_log(\n",
        "            'Total: {:.2f}s\\n'.format(timer_test.toc()), refresh=True\n",
        "        )\n",
        "\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "    def prepare(self, *args):\n",
        "        device = torch.device('cpu' if self.args.cpu else 'cuda')\n",
        "        def _prepare(tensor):\n",
        "            if self.args.precision == 'half': tensor = tensor.half()\n",
        "            return tensor.to(device)\n",
        "\n",
        "        return [_prepare(a) for a in args]\n",
        "\n",
        "    def terminate(self):\n",
        "        if self.args.test_only:\n",
        "            self.test()\n",
        "            return True\n",
        "        else:\n",
        "            epoch = self.optimizer.get_last_epoch() + 1\n",
        "            return epoch >= self.args.epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47z-k3tliGH7"
      },
      "source": [
        "#OPTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEHpKHaNiISO"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='IPT')\n",
        "\n",
        "parser.add_argument('--debug', action='store_true',\n",
        "                    help='Enables debug mode')\n",
        "parser.add_argument('--template', default='.',\n",
        "                    help='You can set various templates in option.py')\n",
        "\n",
        "# Hardware specifications\n",
        "parser.add_argument('--n_threads', type=int, default=6,\n",
        "                    help='number of threads for data loading')\n",
        "parser.add_argument('--cpu', action='store_true',\n",
        "                    help='use cpu only')\n",
        "parser.add_argument('--n_GPUs', type=int, default=1,\n",
        "                    help='number of GPUs')\n",
        "parser.add_argument('--seed', type=int, default=1,\n",
        "                    help='random seed')\n",
        "\n",
        "# Data specifications\n",
        "parser.add_argument('--dir_data', type=str, default='',\n",
        "                    help='dataset directory')\n",
        "parser.add_argument('--dir_demo', type=str, default='../test',\n",
        "                    help='demo image directory')\n",
        "parser.add_argument('--data_train', type=str, default='DIV2K',\n",
        "                    help='train dataset name')\n",
        "parser.add_argument('--data_test', type=str, default='DIV2K',\n",
        "                    help='test dataset name')\n",
        "parser.add_argument('--data_range', type=str, default='1-800/801-810',\n",
        "                    help='train/test data range')\n",
        "parser.add_argument('--ext', type=str, default='sep',\n",
        "                    help='dataset file extension')\n",
        "parser.add_argument('--scale', type=str, default='1',\n",
        "                    help='super resolution scale')\n",
        "parser.add_argument('--patch_size', type=int, default=48,\n",
        "                    help='output patch size')\n",
        "parser.add_argument('--rgb_range', type=int, default=255,\n",
        "                    help='maximum value of RGB')\n",
        "parser.add_argument('--n_colors', type=int, default=3,\n",
        "                    help='number of color channels to use')\n",
        "parser.add_argument('--no_augment', action='store_true',\n",
        "                    help='do not use data augmentation')\n",
        "\n",
        "# Model specifications\n",
        "parser.add_argument('--model', default='ipt',\n",
        "                    help='model name')\n",
        "parser.add_argument('--n_feats', type=int, default=64,\n",
        "                    help='number of feature maps')\n",
        "parser.add_argument('--shift_mean', default=True,\n",
        "                    help='subtract pixel mean from the input')\n",
        "parser.add_argument('--precision', type=str, default='single',\n",
        "                    choices=('single', 'half'),\n",
        "                    help='FP precision for test (single | half)')\n",
        "\n",
        "# Training specifications\n",
        "parser.add_argument('--reset', action='store_true',\n",
        "                    help='reset the training')\n",
        "parser.add_argument('--test_every', type=int, default=1000,\n",
        "                    help='do test per every N batches')\n",
        "parser.add_argument('--epochs', type=int, default=300,\n",
        "                    help='number of epochs to train')\n",
        "parser.add_argument('--batch_size', type=int, default=16,\n",
        "                    help='input batch size for training')\n",
        "parser.add_argument('--test_batch_size', type=int, default=1,\n",
        "                    help='input batch size for training')\n",
        "parser.add_argument('--crop_batch_size', type=int, default=64,\n",
        "                    help='input batch size for training')\n",
        "parser.add_argument('--split_batch', type=int, default=1,\n",
        "                    help='split the batch into smaller chunks')\n",
        "parser.add_argument('--self_ensemble', action='store_true',\n",
        "                    help='use self-ensemble method for test')\n",
        "parser.add_argument('--test_only', default = True,\n",
        "                    help='set this option to test the model')\n",
        "parser.add_argument('--gan_k', type=int, default=1,\n",
        "                    help='k value for adversarial loss')\n",
        "\n",
        "# Optimization specifications\n",
        "parser.add_argument('--lr', type=float, default=1e-4,\n",
        "                    help='learning rate')\n",
        "parser.add_argument('--decay', type=str, default='200',\n",
        "                    help='learning rate decay type')\n",
        "parser.add_argument('--gamma', type=float, default=0.5,\n",
        "                    help='learning rate decay factor for step decay')\n",
        "parser.add_argument('--optimizer', default='ADAM',\n",
        "                    choices=('SGD', 'ADAM', 'RMSprop'),\n",
        "                    help='optimizer to use (SGD | ADAM | RMSprop)')\n",
        "parser.add_argument('--momentum', type=float, default=0.9,\n",
        "                    help='SGD momentum')\n",
        "parser.add_argument('--betas', type=tuple, default=(0.9, 0.999),\n",
        "                    help='ADAM beta')\n",
        "parser.add_argument('--epsilon', type=float, default=1e-8,\n",
        "                    help='ADAM epsilon for numerical stability')\n",
        "parser.add_argument('--weight_decay', type=float, default=0,\n",
        "                    help='weight decay')\n",
        "parser.add_argument('--gclip', type=float, default=0,\n",
        "                    help='gradient clipping threshold (0 = no clipping)')\n",
        "\n",
        "# Loss specifications\n",
        "parser.add_argument('--loss', type=str, default='1*L1',\n",
        "                    help='loss function configuration')\n",
        "parser.add_argument('--skip_threshold', type=float, default='1e8',\n",
        "                    help='skipping batch that has large error')\n",
        "\n",
        "# Log specifications\n",
        "parser.add_argument('--save', type=str, default='/content/gdrive/MyDrive/project_folder/datasets/train_results/',\n",
        "                    help='file name to save')\n",
        "parser.add_argument('--load', type=str, default='',\n",
        "                    help='file name to load')\n",
        "parser.add_argument('--resume', type=int, default=0,\n",
        "                    help='resume from specific checkpoint')\n",
        "parser.add_argument('--save_models', action='store_true',\n",
        "                    help='save all intermediate models')\n",
        "parser.add_argument('--print_every', type=int, default=100,\n",
        "                    help='how many batches to wait before logging training status')\n",
        "parser.add_argument('--save_results', action='store_true',\n",
        "                    help='save output results')\n",
        "parser.add_argument('--save_gt', action='store_true',\n",
        "                    help='save low-resolution and high-resolution images together')\n",
        "\n",
        "#cloud\n",
        "parser.add_argument('--moxfile', type=int, default=1)\n",
        "parser.add_argument('--data_url', type=str,help='path to dataset')\n",
        "parser.add_argument('--train_url', type=str, help='train_dir')\n",
        "parser.add_argument('--pretrain', type=str, default='')\n",
        "parser.add_argument('--load_query', type=int, default=0)\n",
        "\n",
        "#transformer\n",
        "parser.add_argument('--patch_dim', type=int, default=3)\n",
        "parser.add_argument('--num_heads', type=int, default=12)\n",
        "parser.add_argument('--num_layers', type=int, default=12)\n",
        "parser.add_argument('--dropout_rate', type=float, default=0)\n",
        "parser.add_argument('--no_norm', action='store_true')\n",
        "parser.add_argument('--freeze_norm', action='store_true')\n",
        "parser.add_argument('--post_norm', action='store_true')\n",
        "parser.add_argument('--no_mlp', action='store_true')\n",
        "parser.add_argument('--pos_every', action='store_true')\n",
        "parser.add_argument('--no_pos', action='store_true')\n",
        "parser.add_argument('--num_queries', type=int, default=1)\n",
        "\n",
        "#denoise\n",
        "parser.add_argument('--denoise', action='store_true')\n",
        "parser.add_argument('--sigma', type=float, default=30)\n",
        "\n",
        "#derain\n",
        "parser.add_argument('--derain', action='store_true')\n",
        "parser.add_argument('--derain_test', type=int, default=1)\n",
        "\n",
        "#deblur\n",
        "parser.add_argument('--deblur', action='store_true')\n",
        "parser.add_argument('--deblur_test', type=int, default=1)\n",
        "\n",
        "\n",
        "args, unparsed = parser.parse_known_args()\n",
        "\n",
        "args.denoise = True\n",
        "args.sigma= 30\n",
        "args.save_results = True\n",
        "args.data_train = 'DIV2K'\n",
        "args.data_test = 'DIV2K'\n",
        "#args.pretrain ='/content/gdrive/MyDrive/project_folder/pretrained_models/IPT_denoise30.pt'\n",
        "args.pretrain =''\n",
        "args.test_only = False\n",
        "args.dir_data ='/content/gdrive/MyDrive/project_folder/datasets/'\n",
        "\n",
        "args.scale = list(map(lambda x: int(x), args.scale))\n",
        "args.data_train = args.data_train.split('+')\n",
        "args.data_test = args.data_test.split('+')\n",
        "\n",
        "    \n",
        "if args.epochs == 0:\n",
        "    args.epochs = 1e8\n",
        "\n",
        "for arg in vars(args):\n",
        "    if vars(args)[arg] == 'True':\n",
        "        vars(args)[arg] = True\n",
        "    elif vars(args)[arg] == 'False':\n",
        "        vars(args)[arg] = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyDtKZ6fiOk9"
      },
      "source": [
        "#EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeKfWfXNjsdL",
        "outputId": "a5c2cc63-baf9-4cc0-9b54-dfdccca9b98d"
      },
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "\n",
        "execfile('model.py')\n",
        "execfile('utility.py')\n",
        "execfile('datainit_IPT.py')\n",
        "execfile('loss.py')\n",
        "execfile('trainer.py')\n",
        "\n",
        "\n",
        "\n",
        "import model \n",
        "import torch\n",
        "import utility\n",
        "import datainit_IPT\n",
        "import loss\n",
        "import trainer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "#\n",
        "# os.system('pip install einops')\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "checkpoint = utility.checkpoint(args)\n",
        "\n",
        "\n",
        "\n",
        "print (args)\n",
        "\n",
        "print (args.scale)\n",
        "def main():\n",
        "    global model\n",
        "    if checkpoint.ok:\n",
        "        loader = datainit_IPT.Data(args)\n",
        "        _model = model.Model(args, checkpoint)\n",
        "        if args.pretrain != \"\":\n",
        "            if 's3' in args.pretrain:\n",
        "                import moxing as mox\n",
        "                mox.file.copy_parallel(args.pretrain,\"/cache/models/ipt.pt\")\n",
        "                args.pretrain = \"/cache/models/ipt.pt\"\n",
        "            state_dict = torch.load(args.pretrain)\n",
        "            _model.model.load_state_dict(state_dict,strict = False)\n",
        "        _loss = loss.Loss(args, checkpoint) if not args.test_only else None\n",
        "        t = trainer.Trainer(args, loader, _model, _loss, checkpoint)\n",
        "        t.test()\n",
        "        checkpoint.done()\n",
        "            \n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=16, betas=(0.9, 0.999), cpu=False, crop_batch_size=64, data_range='1-800/801-810', data_test=['DIV2K'], data_train=['DIV2K'], data_url=None, deblur=False, deblur_test=1, debug=False, decay='200', denoise=True, derain=False, derain_test=1, dir_data='/content/gdrive/MyDrive/project_folder/datasets/', dir_demo='../test', dropout_rate=0, epochs=300, epsilon=1e-08, ext='sep', freeze_norm=False, gamma=0.5, gan_k=1, gclip=0, load='', load_query=0, loss='1*L1', lr=0.0001, model='ipt', momentum=0.9, moxfile=1, n_GPUs=1, n_colors=3, n_feats=64, n_threads=6, no_augment=False, no_mlp=False, no_norm=False, no_pos=False, num_heads=12, num_layers=12, num_queries=1, optimizer='ADAM', patch_dim=3, patch_size=48, pos_every=False, post_norm=False, precision='single', pretrain='', print_every=100, reset=False, resume=0, rgb_range=255, save='/content/gdrive/MyDrive/project_folder/datasets/train_results/', save_gt=False, save_models=False, save_results=True, scale=[1], seed=1, self_ensemble=False, shift_mean=True, sigma=30, skip_threshold=100000000.0, split_batch=1, template='.', test_batch_size=1, test_every=1000, test_only=False, train_url=None, weight_decay=0)\n",
            "[1]\n",
            "False\n",
            "['DIV2K']\n",
            "div2k\n",
            "[<div2k.DIV2K object at 0x7feac01ed810>]\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7feab9a65550>\n",
            "['DIV2K']\n",
            "DIV2K\n",
            "Making model...\n",
            "Preparing loss function:\n",
            "1.000 * L1\n",
            "\n",
            "Evaluation:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:01, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DIV2K x1]\tPSNR: nan (Best: nan @epoch 1)\n",
            "Forward: 2.07s\n",
            "\n",
            "Saving...\n",
            "Total: 2.23s\n",
            "\n"
          ]
        }
      ]
    }
  ]
}